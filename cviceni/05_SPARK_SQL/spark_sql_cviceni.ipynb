{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Spusteni pyspark\n",
    "\n",
    "`pyspark --master yarn --num-executors 2 --executor-memory 4G --packages com.databricks:spark-csv_2.10:1.5.0 --conf spark.ui.port=1<ddmm>`, kde `<ddmm>` je vas den a mesic narozeni, napr. spark.ui.port=10811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uzitecne importy\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Manual Spark SQL](http://spark.apache.org/docs/1.6.0/api/python/pyspark.sql.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Nacteni dat a zakladni explorace\n",
    "\n",
    "Soubor lyrics.txt obsahuje zaznamy o pisnich vcetne textu. Tento soubor nactete jako DataFrame a pri nacteni definujte schema -- viz nize.\n",
    "\n",
    "* format: CSV\n",
    "* cesta `/user/pascepet/data/`\n",
    "* oddelovac je `','`\n",
    "* schema\n",
    "```\n",
    "id – long\n",
    "album – string\n",
    "rok – integer\n",
    "interpret – string\n",
    "zanr – string\n",
    "text – string\n",
    "```\n",
    "\n",
    "1.1 Nactene DataFrame nakesujte.\n",
    "\n",
    "1.2 Vypiste si ukazku dat.\n",
    "\n",
    "1.3 Zjistete pocet zaznamu (radku) v DataFrame.\n",
    "\n",
    "1.4 Zjistete, kolik pisni ma jako interpreta Boba Dylana ('bob-dylan').\n",
    "\n",
    "1.5 Zjistete, jaky je nejnizsi a nejvyssi uvedeny rok pisne.\n",
    "\n",
    "1.6 Zjistete, ktery zanr ma nejvic pisni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Uprava a cisteni dat\n",
    "\n",
    "2.1 Vyradte vsechny zaznamy, ktere maji uvedeny rok mimo rozmezi 1950--2018. Zjistete, kolik zaznamu v DataFrame zustalo.\n",
    "\n",
    "2.2 Z textu pisne odstrante vsechny znaky `,.:;!?()[]` (obtiznejsi varianta: odstrante vsechny nealfanumericke znaky krome mezer) a text prevedte na mala pismena.\n",
    "\n",
    "2.3 Pridejte sloupec `slova_poc` obsahujici pocet vsech slov pisne, sloupec `slova_poc_unik` obsahujici pocet vsech unikatnich slov pisne a sloupec `slova_poc_unik2` obsahujici pocet vsech unikatnich slov pisne po vyrazeni stop-words. Slova jsou v textu oddelena carkou. Soubor se stop-words je na HDFS: `/user/pascepet/data/stopwords.txt`.\n",
    "\n",
    "2.4 Vysledny DataFrame opet nakesujte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyticke dotazy\n",
    "\n",
    "3.1 Zjistete pocty pisni podle jednotlivych roku.\n",
    "\n",
    "3.2 Zjistete, kolik interpretu ma aspon 500 pisni a kteri to jsou.\n",
    "\n",
    "3.3 Ktery interpret ma v prumeru nejvice unikatnich slov na jednu pisen? A zmeni se to, pokud se budou pocitat jen unikatni slova bez stop-words? (Obtiznejsi varianta: berte v uvahu jen interprety, kteri maji aspon 50 pisni.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Text-mining\n",
    "\n",
    "4.1 Najdete 20 nejcasteji se vyskytujicich slov bez stop-words. (Kazde slovo pocitejte tolikrat, kolikrat je v textu uvedeno.)\n",
    "\n",
    "4.2 Vyberte 3 nejcastejsi slova (krome stop-words) a k DataFrame pridejte tri sloupce s priznaky, zda je v pisni dane slovo aspon jednou uvedeno.\n",
    "\n",
    "4.3 U interpretu s aspon 500 pisnemi (viz 3.2) zjistete, v jakem podilu jejich pisni se vyskytuji tri vami vybrana nejcastejsi slova."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
