{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. copy data from HDFS folder `/user/pascepet/data/teplota-usa.zip` to your HDFS-home folder under some new directory `/user/username/some_new_dir`\n",
    "2. download data from HDFS to your home folder and unzip it. (hint `unzip archive.zip`)\n",
    "3. upload csv files to HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start HIVE CLI using command\n",
    "\n",
    "`beeline -u \"jdbc:hive2://hador-c1.ics.muni.cz:10000/default;principal=hive/hador-c1.ics.muni.cz@ICS.MUNI.CZ\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Create external table\n",
    "\n",
    "- Create your database (if not exists)\n",
    "- Make your database your working database\n",
    "- Create external table name temperature_tmp, csv file is separated by \",\"\n",
    "\n",
    "| Column name | Data type |\n",
    "|:------------|:----------|\n",
    "| stanice     | string    |\n",
    "| mesic       | int       |\n",
    "| den         | int       |\n",
    "| hodina      | int       |\n",
    "| teplota     | double    |\n",
    "| flag        | string    |\n",
    "| latitude    | double    |\n",
    "| longitude   | double    |\n",
    "| vyska       | double    |\n",
    "| stat        | string    |\n",
    "| nazev       | string    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Create internal table\n",
    "\n",
    "- Create internal table named temperature stored as parquet with snappy compression codec\n",
    "- Insert data into internal table. Convert temperature data from 10xFahrenheit to celsius using formula $ (\\frac{F}{10} - 32) \\times \\frac{5}{9} $\n",
    "- Drop external table\n",
    "- Check that data files are still on HDFS (`hdfs:///user/username/teplota/`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Find a state with the highest average temperature in summer (month 6, 7, 8)\n",
    "\n",
    "\n",
    "| State | AVG_TEMP |\n",
    "|:------|:---------|\n",
    "|       |          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Create internal partitioned table\n",
    "\n",
    "- Create table partitioned by month use snappy compression\n",
    "- Insert data into partitioned table\n",
    "- Inspect partitioned folder on HDFS (`/user/hive/warehouse/username.db/`)\n",
    "\n",
    "To enable dynamic partitioning execute this commands\n",
    "\n",
    "```\n",
    "set hive.exec.dynamic.partition=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Advanced SQL\n",
    "\n",
    "I. Find states with the highest average temperature per month \n",
    "\n",
    "| Month | State | AVG_TEMP |\n",
    "|:------|:------|:---------|\n",
    "|       |       |          |\n",
    "\n",
    "\n",
    "II. Find weekly seasonality for each station\n",
    "\n",
    "| station | avg_temp_monday | ... | avg_temp_sunday |\n",
    "|:------|:------|:---------|:---------|\n",
    "|       |       |          ||\n",
    "\n",
    "\n",
    "III. Find the difference between station temperature and state's average temperature\n",
    "\n",
    "| station | diff |\n",
    "|:------|:------|\n",
    "|       |       |\n",
    "\n",
    "\n",
    "\n",
    "(hint [Hive Windowing Functions](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
