{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uzitecne funkce Pythonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delka stringu je: 18\n",
      "String obsahuje slova: ['to', 'be', 'Or', 'NOT', 'to', 'be']\n",
      "String obsahuje unikatni slova: {'be', 'Or', 'NOT', 'to'}\n",
      "String prevedeny na mala pismena:  to be or not to be\n",
      "Delka pole (pocet slov) je: 6\n",
      "Prvni prvek v poli je: to\n",
      "Posledni prvek v poli je: be\n"
     ]
    }
   ],
   "source": [
    "my_string = \"to be Or NOT to be\"\n",
    "my_list = my_string.split()\n",
    "print 'Delka stringu je:', len(my_string)\n",
    "print 'String obsahuje slova:', my_string.split()\n",
    "print 'String obsahuje unikatni slova:', set(my_string.split())\n",
    "print 'String prevedeny na mala pismena: ', my_string.lower()\n",
    "print 'Delka pole (pocet slov) je:', len(my_list)\n",
    "print 'Prvni prvek v poli je:', my_list[0]\n",
    "print 'Posledni prvek v poli je:', my_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prace s regularnimi vyrazy v Pythonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "my_string = \"to be Or NOT to be\"\n",
    "# vyhovuje retezec regularnimu vyrazu?\n",
    "re.search(r'be', my_string)!=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'^be', my_string)!=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to_be_Or_NOT_to_be'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nahrazeni\n",
    "re.sub(r' ', r'_', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o be Or NOT to b'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slozitejsi nahrazeni\n",
    "re.sub(r'^.(.*).$', r'\\1', my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spustit interaktivni shell Spark-pythonu\n",
    "\n",
    "`pyspark --master yarn --num-executors 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priklad z prednasky: word count (nebo Hello hadoop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(verse):    \n",
    "    return verse.split(' ')\n",
    "\n",
    "lines = sc.textFile(\"/user/pascepet/data/bible.txt\")\n",
    "words = lines.flatMap(split_string)\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "counts = pairs.reduceByKey(lambda a, b: a + b)\n",
    "counts.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukol c. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadani\n",
    "\n",
    "Upravte priklad z prednasky o nasledujici vylepseni (v libovolnem poradi):\n",
    "\n",
    "1. Vyberte RDD, ktere je vhodne si pro dalsi vypocty kesovat, a nakesujte ho.\n",
    "1. Na konci seradte slova podle cetnosti sestupne (Hint: sortBy nebo sortByKey).\n",
    "1. Pocitejte slovo jako stejne bez ohledu na velikost pismen.\n",
    "1. Neberte v uvahu zacatek radku (nazev biblicke knihy a kod kapitola:vers -- je oddelen od textu tabulatorem).\n",
    "1. Odstrante z textu vsechny nealfanumericke znaky (napr. '.', ':', '-', -- nebo aspon nektere z nich)\n",
    "\n",
    "### Data\n",
    "\n",
    "`/user/pascepet/data/bible.txt` na HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukol c. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadani \n",
    "\n",
    "a) Spocitejte pocet slov v kazdem versi (1 vers = 1 radek) a najdete verse s nejvetsim a nejmensim poctem slov.  \n",
    "b) Provedte stejny vypocet jako v bode a), ale pocitejte jen unikatni slova v kazdem versi.\n",
    "\n",
    "### Data\n",
    "\n",
    "`/user/pascepet/bible.txt` na HDFS\n",
    "\n",
    "### Ocekavany vystup\n",
    "\n",
    "| verse_id | pocet_slov |  \n",
    "| -------- | ----------:|  \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukol c. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadani\n",
    "\n",
    "a) Zjistete, ktery stat ma nejvyssi prumernou teplotu z mereni jen za mesice 6--8. Teplotu uvedte ve stupnich Celsia.  \n",
    "b) Pro kazdy mesic vypiste stat, ktery ma nejvyssi prumernou teplotu z mereni za tento mesic.\n",
    "\n",
    "### Data\n",
    "\n",
    "1. Na lokalnim filesystemu (tj. ne na HDFS) je vychozi soubor `/home/pascepet/fel_bigdata/data/teplota-usa.zip`. Tento soubor si zkopírujte do svého pracovního adresáře na lokálním filesystemu a rozbalte si ho tam.\n",
    "1. Po rozbaleni dostanete dva soubory CSV. Spojte si je do souboru `teplota.csv`.\n",
    "1. Soubor `teplota.csv` zkopirujte na HDFS do sveho pracovniho adresare.\n",
    "\n",
    "### Vstupni data\n",
    "\n",
    "CSV soubor ma jako oddelovac znak ','. Take obsahuje hlavicky s nazvy sloupcu, ktere je potreba pri zpracovani odstranit.    \n",
    "Teplota je uvedena v 10 * stupne Fahrenheita. Nektere radky neobsahuji zadnou namerenou teplotu (prazdny retezec).\n",
    "\n",
    "**Sloupce:** id_stanice, mesic, den, hodina, teplota, flag, latitude, longitude, vyska, stat, nazev\n",
    "\n",
    "\n",
    "### Ocekavany vystup\n",
    "\n",
    "V zadani a)\n",
    "\n",
    "| stat | prum_teplota |  \n",
    "| ---- | ------------:|  \n",
    "\n",
    "V zadani b)\n",
    "\n",
    "| mesic | stat | prum_teplota |  \n",
    "| ----- | ---- | ------------:|  \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonusovy ukol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadani\n",
    "\n",
    "V ukolu 1 vyradte ze zpracovani tzv. stop-slova.\n",
    "\n",
    "Hint: Pouzijte [Spark broadcast](https://spark.apache.org/docs/latest/rdd-programming-guide.html#broadcast-variables)\n",
    "\n",
    "### Data\n",
    "\n",
    "`/user/pascepet/data/bible.txt` na HDFS    \n",
    "`/user/pascepet/data/stopwords.txt` na HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nacist stop slova do mnoziny muzete pomoci prikazu\n",
    "sw = set(sc.textFile('/user/pascepet/data/stopwords.txt').collect())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
